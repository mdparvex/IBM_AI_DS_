{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Overcomplete Autoencoders for Denoising  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, you will see how Overcomplete Autoencoders  can be used for Denoising. that </p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#AF\">auxiliary function and Imports</a></li>\n",
    "    <li><a href=\"#LD\">Load Data</a></li>\n",
    "    <li><a href=\"#CA\">Compare Autoencoders </a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>20 min</strong></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"AF\">Auxiliary Function and Imports </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need for the lab\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object with noise <code>x_</code> will be the noisy sample, and <code>x</code> will be the correct input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data object\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, N_SAMPLES=400, noise_std=0.1, train=True):\n",
    "        self.x=torch.zeros(( N_SAMPLES,2))\n",
    "        \n",
    "        self.x_=torch.zeros(( N_SAMPLES,2))\n",
    "        \n",
    "        self.x[:,0] = torch.linspace(0, 2, N_SAMPLES)\n",
    "        self.x[self.x[:,0]<1,1]=1\n",
    "        self.x[:,1]=self.x[:,1]+1\n",
    "        self.len=N_SAMPLES\n",
    "        if train != True:\n",
    "            torch.manual_seed(1)\n",
    "            self.x_[:,0] = self.x[:,0]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            self.x_[:,1] = self.x[:,1]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            \n",
    "        else:\n",
    "            torch.manual_seed(0)\n",
    "            self.x_[:,0] = self.x[:,0]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            self.x_[:,1] = self.x[:,1]+ noise_std * torch.randn(N_SAMPLES)\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):    \n",
    "        return self.x_[index,:], self.x[index,:]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Plot the data\n",
    "    def plot(self):\n",
    "        plt.figure(figsize = (6.1, 10))\n",
    "        plt.scatter(self.x_[:,0].numpy(),self.x_[:,1].numpy(), label=\"Noisy function\")\n",
    "        plt.plot(self.x[:,0].numpy(), self.x[:,1].numpy() ,label=\"True Function\", color='orange')\n",
    "        plt.xlabel(\"x_{1}\")\n",
    "        plt.ylabel(\"x_{2}\")\n",
    "        plt.xlim((0, 2))\n",
    "        #plt.ylim((0, 2.5))\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will plot the data points before and after they are passed through the autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(model,dataset):\n",
    "\n",
    "    xhat_points=model(dataset.x_)\n",
    "    f_xat=model(dataset.x)\n",
    "\n",
    "    plt.scatter(dataset.x_[:,0].numpy(),dataset.x_[:,1].numpy(), label=\"x_\")\n",
    "    plt.plot(dataset.x[:,0].numpy(), dataset.x[:,1].numpy(),'g' ,label=\"f\",)\n",
    "    plt.plot(f_xat[:,0].detach().numpy(), f_xat[:,1].detach().numpy() ,label=\"fhat\", color='r')\n",
    "    plt.scatter(xhat_points[:,0].detach().numpy(),xhat_points[:,1].detach().numpy(), label=\"xhat\")    \n",
    "   \n",
    "    plt.legend() \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"LD\">Load Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset object and plot the dataset\n",
    "\n",
    "train_dataset = Data(N_SAMPLES=2000, noise_std=0.1)\n",
    "train_dataset .plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some validation data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset object\n",
    "\n",
    "validation_dataset = Data(N_SAMPLES=400, noise_std=0.1,train=False)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset , batch_size=2)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model_Cost\">Create the Model, Optimizer, and Total Loss Function (Cost)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom module with three layers. <code>in_size</code> is the size of the input features, <code>n_hidden</code> is the size of the layers, and <code>out_size</code> is the size. <code>p</code> is dropout probability. The default is 0 which is no dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model,train_loader,validation_loader,optimizer,n_epochs=4):   \n",
    "    #global variable \n",
    "    cost_list_training =[]\n",
    "    cost_list_validation =[]\n",
    "    for epoch in range(n_epochs):\n",
    "        cost_training=0\n",
    "        for x_tilde, x in train_loader:\n",
    "           \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            xhat = model(x_tilde)\n",
    "            loss = criterion(xhat , x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cost_training+=loss.data\n",
    "        \n",
    "        cost_list_training.append(cost_training)\n",
    "    \n",
    "       \n",
    "\n",
    "        #perform a prediction on the validation  data  \n",
    "        cost_val=0\n",
    "        for x_tilde, x in validation_loader:\n",
    "            \n",
    "            model.eval()\n",
    "            xhat = model(x_tilde)\n",
    "            loss = criterion(xhat, x)\n",
    "            cost_val+=loss.data\n",
    "            \n",
    "            \n",
    "        \n",
    "        cost_list_validation.append(cost_val)\n",
    "     \n",
    "    return cost_list_training, cost_list_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot training cost and validation cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val(cost_list,accuracy_list,val_data_label ='accuracy'):\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(cost_list, color = color)\n",
    "    ax1.set_xlabel('epoch ', color = color)\n",
    "    ax1.set_ylabel('total cost', color = color)\n",
    "    ax1.tick_params(axis = 'y', color = color)\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel(val_data_label, color = color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(accuracy_list, color = color)\n",
    "    ax2.tick_params(axis = 'y', color = color)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"CA\">Compare Autoencoders</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear autoencoder custom module and an autoencoder custom module  with a Rulu function encoder and Selu decoder function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, input_dim=2, encoding_dim=2):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim,encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim,input_dim)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x =  self.encoder(x)\n",
    "        \n",
    "        x=self.decoder(x)\n",
    "      \n",
    "        return x\n",
    "    \n",
    "    def code(self,x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class AutoEncoder_non_lin(nn.Module):   \n",
    "    def __init__(self, input_dim=2, encoding_dim=2):\n",
    "        super(AutoEncoder_non_lin, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim,encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim,input_dim)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x =  torch.relu(self.encoder(x))\n",
    "        \n",
    "        x=torch.selu(self.decoder(x))\n",
    "      \n",
    "        return x\n",
    "    \n",
    "    def code(self,x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of a linear under complete autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/DL0110EN/Version_3/Chapter_10/images/under_complete%20.png\" width=\"400\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear=AutoEncoder(2,1)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model_linear.parameters(), lr = learning_rate)\n",
    "train_cost,validation_cost =train_model(model=model_linear,n_epochs=10,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(validation_cost, train_cost,val_data_label ='validation  cost')\n",
    "\n",
    "plot_points(model_linear,validation_dataset)\n",
    "print(\"validation  cost\",validation_cost[-1] )\n",
    "print(\"training cost\",train_cost[-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of a linear overcomplete autoencoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/DL0110EN/Version_3/Chapter_10/images/over_complete%20.png\" width=\"400\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear=AutoEncoder(2,10)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model_linear.parameters(), lr = learning_rate)\n",
    "train_cost,validation_cost=train_model(model=model_linear,n_epochs=10,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(validation_cost, train_cost,val_data_label ='validation  cost')\n",
    "\n",
    "plot_points(model_linear,validation_dataset)\n",
    "print(\"validation  cost\",validation_cost[-1] )\n",
    "print(\"training cost\",train_cost[-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example an overcomplete autoencoder with a  Rulu function encoder and Selu decoder function.This will take more iteration to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/DL0110EN/Version_3/Chapter_10/images/non_linear%20.png\" width=\"400\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_non_linear=AutoEncoder_non_lin(2,10)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model_non_linear.parameters(), lr = learning_rate)\n",
    "train_cost,validation_cost=train_model(model=model_non_linear,n_epochs=100,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(validation_cost, train_cost,val_data_label ='validation  cost')\n",
    "plot_points(model_non_linear,validation_dataset)\n",
    "print(\"validation  cost\",validation_cost[-1] )\n",
    "print(\"training cost\",train_cost[-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see the nonlinear autoencoder performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
