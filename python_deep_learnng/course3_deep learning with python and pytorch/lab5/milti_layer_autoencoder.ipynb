{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep  Autoencoder- Noisey manifold </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, you will create a deep autoencoder for noise removal in a non-linear manifold..</p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n",
    "    <li><a href=\"#Model_Cost\">Function to Train, the Model </a></li>\n",
    "    <li><a href=\"#CM\">Build Custom  module </a></li>\n",
    "    <li><a href=\"#tv\">Training and Validate Model </a></li>\n",
    "</ul>\n",
    "\n",
    "<p>Estimated Time Needed: <strong>20 min</strong></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need for the lab\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a noisy manifold dataset class example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data object\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, N_SAMPLES=400, noise_std=0.1, train=True):\n",
    "        self.x=torch.zeros(( N_SAMPLES,2))\n",
    "        self.x_=torch.zeros(( N_SAMPLES,2))\n",
    "    \n",
    "        self.x[:,0] = torch.linspace(-2, 2, N_SAMPLES)\n",
    "        \n",
    "        self.x[:,1] = (self.x[:,0] **3)\n",
    "        self.len=N_SAMPLES\n",
    "        if train != True:\n",
    "            torch.manual_seed(1)\n",
    "            self.x_[:,0] = self.x[:,0]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            self.x_[:,1] = self.x[:,1]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            \n",
    "        else:\n",
    "            torch.manual_seed(0)\n",
    "            self.x_[:,0] = self.x[:,0]+ noise_std * torch.randn(N_SAMPLES)\n",
    "            self.x_[:,1] = self.x[:,1]+ noise_std * torch.randn(N_SAMPLES)\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):    \n",
    "        return self.x_[index,:], self.x[index,:]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Plot the data\n",
    "    def plot(self):\n",
    "        plt.figure(figsize = (6.1, 10))\n",
    "        plt.scatter(self.x_[:,0].numpy(),self.x_[:,1].numpy(), label=\"Noisy function\")\n",
    "        plt.plot(self.x[:,0].numpy(), self.x[:,1].numpy() ,label=\"True Function\", color='orange')\n",
    "        plt.xlabel(\"x_{1}\")\n",
    "        plt.ylabel(\"x_{2}\")\n",
    "        plt.xlim((-1, 1))\n",
    "        plt.ylim((-2, 2.5))\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will be used to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(model,dataset,title=\"autoencoder\"):\n",
    "\n",
    "    xhat_points=model(dataset.x_)\n",
    "    f_xat=model(dataset.x)\n",
    "\n",
    "    ax=plt.subplot(121)\n",
    "    ax.scatter(xhat_points[:,0].detach().numpy(),xhat_points[:,1].detach().numpy(), label=\"xhat\")\n",
    "    ax.scatter(dataset.x_[:,0].numpy(),dataset.x_[:,1].numpy(), label=\"xhat\")\n",
    "    ax.plot(f_xat[:,0].detach().numpy(), f_xat[:,1].detach().numpy() ,label=\"fhat\", color='r')\n",
    "    ax.plot(dataset.x[:,0].numpy(), dataset.x[:,1].numpy(),'g' ,label=\"f\",)\n",
    "    ax.set_title(title)\n",
    "    ax.legend() \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset object and plot the dataset\n",
    "\n",
    "train_dataset = Data(N_SAMPLES=1000, noise_std=0.1)\n",
    "train_dataset .plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object for validation data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset object\n",
    "\n",
    "validation_dataset = Data(N_SAMPLES=400, noise_std=0.1,train=False)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validiaon loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset , batch_size=2)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model_Cost\">Create the Model, Optimizer, and Total Loss Function (Cost)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to train the autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_loader,validation_loader,optimizer,n_epochs=4):   \n",
    "    #global variable \n",
    "    cost_list_training =[]\n",
    "    cost_list_validation =[]\n",
    "    for epoch in range(n_epochs):\n",
    "        cost_training=0\n",
    "        for x_tilde, x in train_loader:\n",
    "           \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            xhat = model(x_tilde)\n",
    "            loss = criterion(xhat , x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cost_training+=loss.data\n",
    "        \n",
    "        cost_list_training.append(cost_training)\n",
    "    \n",
    "       \n",
    "\n",
    "        #perform a prediction on the validation  data  \n",
    "        cost_val=0\n",
    "        for x_test, y_test in validation_loader:\n",
    "            \n",
    "            model.eval()\n",
    "            z = model(x_test)\n",
    "            loss = criterion(z, x_test)\n",
    "            cost_val+=loss.data\n",
    "            \n",
    "            \n",
    "        \n",
    "        cost_list_validation.append(cost_val)\n",
    "     \n",
    "    return cost_list_training, cost_list_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will plot the training cost and validation cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val(cost_list,accuracy_list,val_data_label ='accuracy'):\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(cost_list, color = color)\n",
    "    ax1.set_xlabel('epoch ', color = color)\n",
    "    ax1.set_ylabel('total loss', color = color)\n",
    "    ax1.tick_params(axis = 'y', color = color)\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel(val_data_label, color = color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(accuracy_list, color = color)\n",
    "    ax2.tick_params(axis = 'y', color = color)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"CM\">Build Custom  module  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Autoencoder custom modules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Linear autoencoder:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, input_dim=2, encoding_dim=2):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim,encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim,input_dim)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x =  self.encoder(x)\n",
    "        \n",
    "        x=self.decoder(x)\n",
    "      \n",
    "        return x\n",
    "    \n",
    "    def code(self,x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Shallow  Nonlinear Decoding and Encoding Function </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class AutoEncoder_s(nn.Module):   \n",
    "    def __init__(self, input_dim=2, encoding_dim=2):\n",
    "        super(AutoEncoder_s, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim,encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim,input_dim)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x =  torch.sigmoid(self.encoder(x))\n",
    "        \n",
    "        x=torch.selu(self.decoder(x))\n",
    "      \n",
    "        return x\n",
    "    \n",
    "    def code(self,x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Deep autoencoder  Nonlinear Decoding and Encoding Function</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoderone_hidden(nn.Module):\n",
    "    def __init__(self, input_dim=2,encoding_dim_1=2,encoding_dim_2=2):\n",
    "        super(Autoencoderone_hidden,self).__init__()\n",
    "      \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim_1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(encoding_dim_1, encoding_dim_2))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim_2, encoding_dim_1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(encoding_dim_1, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"tv\">Training and Validate Model </h2>\n",
    "\n",
    "In this section, we will train and validate the different autoencoders. We have the linear autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear=AutoEncoder(2,1000)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model_linear.parameters(), lr = learning_rate)\n",
    "accuracy_list, lost_list=train_model(model=model_linear,n_epochs=10,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(accuracy_list, lost_list,val_data_label ='Cost')\n",
    "\n",
    "plot_points(model_linear,validation_dataset,\"linear overcomplete \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have the shallow autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu=AutoEncoder_s(2,1000)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model_relu.parameters(), lr = learning_rate)\n",
    "accuracy_list, lost_list=train_model(model=model_relu,n_epochs=10,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(accuracy_list, lost_list,val_data_label ='Cost')\n",
    "plot_points(model_relu,validation_dataset,\"non-linear overcomplete \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, we have the deep autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Autoencoderone_hidden(2,20,20)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "accuracy_list, lost_list=train_model(model=model,n_epochs=20,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "plot_train_val(accuracy_list, lost_list,val_data_label ='Cost')\n",
    "plt.show()\n",
    "plot_points(model,validation_dataset,\"deep overcomplete \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the deep autoencoder performs better on the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
